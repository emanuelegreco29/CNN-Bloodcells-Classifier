{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw_-hFm6bjY6"
   },
   "source": [
    "## ğŸŒ Connect to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2S4GWr3Uoa8",
    "outputId": "ebd2c29f-2957-4bb2-ca5d-a1f2da4ea0bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n",
      "/gdrive/My Drive\n",
      "/gdrive/My Drive/[2024-2025] AN2DL Homework 1\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My Drive/\n",
    "%cd [2024-2025] AN2DL Homework 1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRQSldIb4i1V"
   },
   "source": [
    "## ğŸ›  Fix Codabench Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-9WtuCR4iQk",
    "outputId": "43b1ca23-dcb9-4dfe-a429-b29ae1278458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Creates a file in which we specify the versions of the libraries we want\n",
    "%%writefile requirements.txt\n",
    "tensorflow==2.17.0\n",
    "keras==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "lsNAwawq8PNr",
    "outputId": "137d56db-fbf3-43e6-e2d4-71dee296db81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.17.0 (from -r requirements.txt (line 1))\n",
      "  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting keras==3.4.1 (from -r requirements.txt (line 2))\n",
      "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (2.17.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1->-r requirements.txt (line 2)) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1->-r requirements.txt (line 2)) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1->-r requirements.txt (line 2)) (0.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.17.0->-r requirements.txt (line 1)) (0.45.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->-r requirements.txt (line 1)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->-r requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1->-r requirements.txt (line 2)) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.4.1->-r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0->-r requirements.txt (line 1)) (3.0.2)\n",
      "Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras, tensorflow\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.5.0\n",
      "    Uninstalling keras-3.5.0:\n",
      "      Successfully uninstalled keras-3.5.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.17.1\n",
      "    Uninstalling tensorflow-2.17.1:\n",
      "      Successfully uninstalled tensorflow-2.17.1\n",
      "Successfully installed keras-3.4.1 tensorflow-2.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7IqZP5Iblna"
   },
   "source": [
    "## âš™ï¸ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "id": "CO6_Ft_8T56A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as tfk\n",
    "from keras import layers as tfkl\n",
    "\n",
    "# Import other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seeds for NumPy and TensorFlow\n",
    "seed = 29\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed);\n",
    "\n",
    "# Reduce TensorFlow verbosity\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## â³ Load and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLaoDaG1V1Yg",
    "outputId": "5a424234-98e4-4538-99e6-ac99d6925968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial X shape:  (13759, 96, 96, 3)\n",
      "Initial y shape:  (13759, 1)\n",
      "Final X shape:  (11959, 96, 96, 3)\n",
      "Final y shape:  (11959, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = np.load('training_set.npz')\n",
    "\n",
    "# Put images on X and labels on y\n",
    "X = data['images']\n",
    "y = data['labels']\n",
    "\n",
    "print(\"Initial X shape: \", X.shape)\n",
    "print(\"Initial y shape: \", y.shape)\n",
    "\n",
    "# Delete outliers from the dataset\n",
    "delete_index = 11958\n",
    "X = X[:delete_index + 1]\n",
    "y = y[:delete_index + 1]\n",
    "\n",
    "print(\"Final X shape: \", X.shape)\n",
    "print(\"Final y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5a0oGBH_hjd"
   },
   "source": [
    "## ğŸš† Split into train, validation and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tcKedqJg__oK",
    "outputId": "f5936850-f516-42d7-ea06-87ab3126d8df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:\t (9567, 96, 96, 3) (9567, 8)\n",
      "Validation set shape:\t (1196, 96, 96, 3) (1196, 8)\n",
      "Test set shape:\t\t (1196, 96, 96, 3) (1196, 8)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into a training + validation set, and a separate test set\n",
    "# The test set is the 10% of the whole dataset\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.1,\n",
    "    stratify=y,\n",
    "    random_state=seed)\n",
    "\n",
    "# Further split the training + validation set into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=len(X_test),\n",
    "    stratify=y_train_val,\n",
    "    random_state=seed)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = tfk.utils.to_categorical(y_train, 8)\n",
    "y_val = tfk.utils.to_categorical(y_val, 8)\n",
    "y_test = tfk.utils.to_categorical(y_test, 8)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print('Training set shape:\\t', X_train.shape, y_train.shape)\n",
    "print('Validation set shape:\\t', X_val.shape, y_val.shape)\n",
    "print('Test set shape:\\t\\t', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW5huZxzGInt"
   },
   "source": [
    "## ğŸ§® Define Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q42LjE5QGKc_"
   },
   "outputs": [],
   "source": [
    "# Input shape for the model\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Output shape for the model\n",
    "output_shape = y_train.shape[1]\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 100\n",
    "\n",
    "# Number of samples passed to the network at each training step\n",
    "batch_size = 16\n",
    "\n",
    "# Learning rate: step size for updating the model's weights\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# L2 Lambda for regularization\n",
    "l2_lambda = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7rRsq2pXQfH"
   },
   "source": [
    "## ğŸ”¨ Import and tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94n95sZ4XTtY",
    "outputId": "8b7fcd22-476d-430c-987b-63e0e48fea87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/applications/mobilenet_v3.py:452: UserWarning: `input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  return MobileNetV3(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
      "\u001b[1m4334752/4334752\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Import and initialize MobileNetV3\n",
    "model = tfk.applications.MobileNetV3Small(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=input_shape,\n",
    "    pooling='avg',\n",
    "    classes=output_shape,\n",
    "    classifier_activation='softmax',\n",
    "    include_preprocessing=True\n",
    ")\n",
    "\n",
    "# Initialize regularizer\n",
    "regularizer = tfk.regularizers.L2(l2_lambda)\n",
    "\n",
    "# Freeze all layers to use the model solely as a feature extractor\n",
    "model.trainable = False\n",
    "\n",
    "# Create input layer\n",
    "inputs = tfkl.Input(shape=input_shape)\n",
    "\n",
    "# Connect model with inputs\n",
    "x = model(inputs, training=False)\n",
    "\n",
    "# Add layers\n",
    "x = tfkl.Dense(1024, activation='relu', kernel_regularizer=regularizer)(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dropout(0.5)(x)\n",
    "x = tfkl.Dense(1024, activation='relu', kernel_regularizer=regularizer)(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dropout(0.5)(x)\n",
    "\n",
    "# Setup Fully Connected Blocks\n",
    "x = tfkl.Dropout(rate=0.3)(x)\n",
    "outputs = tfkl.Dense(units=output_shape, activation='softmax', dtype='float32')(x)\n",
    "\n",
    "# Connect input and output\n",
    "model = tfk.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "loss = tfk.losses.CategoricalCrossentropy()\n",
    "optimizer = tfk.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "metrics = ['accuracy']\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSliIxBvbs2Q"
   },
   "source": [
    "## ğŸ§  Train the Model for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5sr8CzivVdvI"
   },
   "outputs": [],
   "source": [
    "# Create an EarlyStopping callback\n",
    "early_stopping = tfk.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Create a LearningRate Scheduler, which reduces learning rate if val_loss doesn't improve\n",
    "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Store the callback in a list\n",
    "callbacks = [early_stopping, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ox9jqYyyUJo0",
    "outputId": "c88a80fe-724b-4998-c09f-1c6f5420cca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.1832 - loss: 3.3659 - val_accuracy: 0.6789 - val_loss: 0.9908 - learning_rate: 1.0000e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.4251 - loss: 2.0162 - val_accuracy: 0.7559 - val_loss: 0.7522 - learning_rate: 1.0000e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5326 - loss: 1.6274 - val_accuracy: 0.7918 - val_loss: 0.6501 - learning_rate: 1.0000e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5891 - loss: 1.3981 - val_accuracy: 0.8110 - val_loss: 0.5964 - learning_rate: 1.0000e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6261 - loss: 1.2525 - val_accuracy: 0.8211 - val_loss: 0.5605 - learning_rate: 1.0000e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6553 - loss: 1.1991 - val_accuracy: 0.8261 - val_loss: 0.5321 - learning_rate: 1.0000e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.6828 - loss: 1.0921 - val_accuracy: 0.8370 - val_loss: 0.5097 - learning_rate: 1.0000e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6883 - loss: 1.0662 - val_accuracy: 0.8411 - val_loss: 0.4940 - learning_rate: 1.0000e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7062 - loss: 1.0152 - val_accuracy: 0.8520 - val_loss: 0.4780 - learning_rate: 1.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7182 - loss: 0.9461 - val_accuracy: 0.8570 - val_loss: 0.4659 - learning_rate: 1.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7265 - loss: 0.9492 - val_accuracy: 0.8595 - val_loss: 0.4504 - learning_rate: 1.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7349 - loss: 0.9232 - val_accuracy: 0.8587 - val_loss: 0.4421 - learning_rate: 1.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7381 - loss: 0.8861 - val_accuracy: 0.8645 - val_loss: 0.4345 - learning_rate: 1.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7462 - loss: 0.8629 - val_accuracy: 0.8662 - val_loss: 0.4265 - learning_rate: 1.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7530 - loss: 0.8561 - val_accuracy: 0.8687 - val_loss: 0.4190 - learning_rate: 1.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.8362 - val_accuracy: 0.8729 - val_loss: 0.4103 - learning_rate: 1.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7648 - loss: 0.8010 - val_accuracy: 0.8746 - val_loss: 0.4026 - learning_rate: 1.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7723 - loss: 0.7766 - val_accuracy: 0.8763 - val_loss: 0.3961 - learning_rate: 1.0000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7678 - loss: 0.8039 - val_accuracy: 0.8771 - val_loss: 0.3912 - learning_rate: 1.0000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7702 - loss: 0.7842 - val_accuracy: 0.8804 - val_loss: 0.3864 - learning_rate: 1.0000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7732 - loss: 0.7630 - val_accuracy: 0.8804 - val_loss: 0.3812 - learning_rate: 1.0000e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7826 - loss: 0.7245 - val_accuracy: 0.8821 - val_loss: 0.3793 - learning_rate: 1.0000e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7877 - loss: 0.7117 - val_accuracy: 0.8829 - val_loss: 0.3752 - learning_rate: 1.0000e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7953 - loss: 0.6910 - val_accuracy: 0.8846 - val_loss: 0.3710 - learning_rate: 1.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7929 - loss: 0.7010 - val_accuracy: 0.8846 - val_loss: 0.3666 - learning_rate: 1.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.6638 - val_accuracy: 0.8880 - val_loss: 0.3620 - learning_rate: 1.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7935 - loss: 0.6983 - val_accuracy: 0.8896 - val_loss: 0.3579 - learning_rate: 1.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7961 - loss: 0.6793 - val_accuracy: 0.8880 - val_loss: 0.3552 - learning_rate: 1.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7926 - loss: 0.6950 - val_accuracy: 0.8896 - val_loss: 0.3523 - learning_rate: 1.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8055 - loss: 0.6754 - val_accuracy: 0.8913 - val_loss: 0.3512 - learning_rate: 1.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8076 - loss: 0.6551 - val_accuracy: 0.8921 - val_loss: 0.3465 - learning_rate: 1.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8033 - loss: 0.6497 - val_accuracy: 0.8930 - val_loss: 0.3442 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8114 - loss: 0.6046 - val_accuracy: 0.8955 - val_loss: 0.3413 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8074 - loss: 0.6306 - val_accuracy: 0.8972 - val_loss: 0.3388 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8154 - loss: 0.6274 - val_accuracy: 0.8972 - val_loss: 0.3353 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.6181 - val_accuracy: 0.9013 - val_loss: 0.3312 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8213 - loss: 0.5856 - val_accuracy: 0.9005 - val_loss: 0.3300 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8107 - loss: 0.6197 - val_accuracy: 0.9013 - val_loss: 0.3281 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8255 - loss: 0.5909 - val_accuracy: 0.8997 - val_loss: 0.3269 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8232 - loss: 0.6071 - val_accuracy: 0.9022 - val_loss: 0.3221 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8268 - loss: 0.5822 - val_accuracy: 0.9064 - val_loss: 0.3210 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8188 - loss: 0.5948 - val_accuracy: 0.9047 - val_loss: 0.3175 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.5793 - val_accuracy: 0.9072 - val_loss: 0.3155 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8329 - loss: 0.5533 - val_accuracy: 0.9072 - val_loss: 0.3156 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8337 - loss: 0.5487 - val_accuracy: 0.9080 - val_loss: 0.3132 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8292 - loss: 0.5692 - val_accuracy: 0.9072 - val_loss: 0.3131 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8349 - loss: 0.5613 - val_accuracy: 0.9089 - val_loss: 0.3108 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8361 - loss: 0.5473 - val_accuracy: 0.9105 - val_loss: 0.3096 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8370 - loss: 0.5377 - val_accuracy: 0.9114 - val_loss: 0.3078 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8314 - loss: 0.5515 - val_accuracy: 0.9130 - val_loss: 0.3066 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 0.5333 - val_accuracy: 0.9114 - val_loss: 0.3055 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8358 - loss: 0.5419 - val_accuracy: 0.9114 - val_loss: 0.3035 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8338 - loss: 0.5438 - val_accuracy: 0.9130 - val_loss: 0.3037 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8386 - loss: 0.5275 - val_accuracy: 0.9139 - val_loss: 0.3038 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8443 - loss: 0.5061 - val_accuracy: 0.9156 - val_loss: 0.2996 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8438 - loss: 0.5148 - val_accuracy: 0.9139 - val_loss: 0.2998 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8439 - loss: 0.5192 - val_accuracy: 0.9156 - val_loss: 0.2975 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 0.5253 - val_accuracy: 0.9156 - val_loss: 0.2973 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8421 - loss: 0.5139 - val_accuracy: 0.9164 - val_loss: 0.2935 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8444 - loss: 0.5144 - val_accuracy: 0.9147 - val_loss: 0.2934 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8407 - loss: 0.4981 - val_accuracy: 0.9147 - val_loss: 0.2924 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8500 - loss: 0.4821 - val_accuracy: 0.9164 - val_loss: 0.2920 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 0.5118 - val_accuracy: 0.9147 - val_loss: 0.2907 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8426 - loss: 0.4969 - val_accuracy: 0.9181 - val_loss: 0.2879 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8499 - loss: 0.4803 - val_accuracy: 0.9181 - val_loss: 0.2877 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8532 - loss: 0.4757 - val_accuracy: 0.9181 - val_loss: 0.2871 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8556 - loss: 0.4653 - val_accuracy: 0.9181 - val_loss: 0.2867 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8594 - loss: 0.4752 - val_accuracy: 0.9197 - val_loss: 0.2841 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 0.4804 - val_accuracy: 0.9189 - val_loss: 0.2828 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8559 - loss: 0.4655 - val_accuracy: 0.9172 - val_loss: 0.2823 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8505 - loss: 0.4740 - val_accuracy: 0.9206 - val_loss: 0.2808 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8542 - loss: 0.4772 - val_accuracy: 0.9197 - val_loss: 0.2794 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8508 - loss: 0.4806 - val_accuracy: 0.9181 - val_loss: 0.2793 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8592 - loss: 0.4579 - val_accuracy: 0.9214 - val_loss: 0.2783 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8547 - loss: 0.4545 - val_accuracy: 0.9214 - val_loss: 0.2769 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8571 - loss: 0.4527 - val_accuracy: 0.9197 - val_loss: 0.2756 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.4606 - val_accuracy: 0.9222 - val_loss: 0.2740 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8635 - loss: 0.4341 - val_accuracy: 0.9206 - val_loss: 0.2737 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8507 - loss: 0.4595 - val_accuracy: 0.9239 - val_loss: 0.2731 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8595 - loss: 0.4503 - val_accuracy: 0.9239 - val_loss: 0.2723 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8631 - loss: 0.4535 - val_accuracy: 0.9239 - val_loss: 0.2714 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8567 - loss: 0.4368 - val_accuracy: 0.9214 - val_loss: 0.2718 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8594 - loss: 0.4584 - val_accuracy: 0.9239 - val_loss: 0.2700 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.4252 - val_accuracy: 0.9231 - val_loss: 0.2700 - learning_rate: 1.0000e-05\n",
      "Training finished.\n",
      "Final validation accuracy: 92.39%\n"
     ]
    }
   ],
   "source": [
    "tl_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks\n",
    ").history\n",
    "\n",
    "print('Training finished.')\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "tl_final_val_accuracy = round(max(tl_history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {tl_final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file, including final accuracy in the filename\n",
    "tl_model_filename = 'MobileNetV3Small' + str(tl_final_val_accuracy) + '.keras'\n",
    "model.save(tl_model_filename)\n",
    "\n",
    "# Free memory by deleting the model instance\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJfYvaTyenL9"
   },
   "source": [
    "## ğŸ”§ Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vd2tLbkueuTt"
   },
   "outputs": [],
   "source": [
    "# Re-load the model after transfer learning\n",
    "ft_model = tfk.models.load_model(tl_model_filename)\n",
    "\n",
    "# Set the model layers as trainable\n",
    "ft_model.get_layer('MobileNetV3Small').trainable = True\n",
    "\n",
    "# Set all layers as non-trainable\n",
    "for layer in ft_model.get_layer('MobileNetV3Small').layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Enable training only for Conv2D and DepthwiseConv2D layers\n",
    "for i, layer in enumerate(ft_model.get_layer('MobileNetV3Small').layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "id": "t3N_PBk2gqiR"
   },
   "outputs": [],
   "source": [
    "# Set the number of layers to freeze\n",
    "N = 200\n",
    "\n",
    "# Set the first N layers as non-trainable\n",
    "for i, layer in enumerate(ft_model.get_layer('MobileNetV3Small').layers[:N]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "loss = tfk.losses.CategoricalCrossentropy()\n",
    "optimizer = tfk.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "metrics = ['accuracy']\n",
    "ft_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc_dOYkghI92"
   },
   "source": [
    "## ğŸ§  Train Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmWtYFf7hHLc",
    "outputId": "02ebac99-d960-4ad9-b62b-e68bb36cdbf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 23ms/step - accuracy: 0.8578 - loss: 0.4443 - val_accuracy: 0.9231 - val_loss: 0.2728 - learning_rate: 1.0000e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8583 - loss: 0.4513 - val_accuracy: 0.9231 - val_loss: 0.2717 - learning_rate: 1.0000e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8681 - loss: 0.4330 - val_accuracy: 0.9247 - val_loss: 0.2721 - learning_rate: 1.0000e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 0.4565 - val_accuracy: 0.9247 - val_loss: 0.2716 - learning_rate: 1.0000e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8664 - loss: 0.4323 - val_accuracy: 0.9256 - val_loss: 0.2704 - learning_rate: 1.0000e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8682 - loss: 0.4454 - val_accuracy: 0.9247 - val_loss: 0.2705 - learning_rate: 1.0000e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8683 - loss: 0.4498 - val_accuracy: 0.9256 - val_loss: 0.2692 - learning_rate: 1.0000e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8647 - loss: 0.4274 - val_accuracy: 0.9256 - val_loss: 0.2681 - learning_rate: 1.0000e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8683 - loss: 0.4287 - val_accuracy: 0.9264 - val_loss: 0.2674 - learning_rate: 1.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8690 - loss: 0.4260 - val_accuracy: 0.9256 - val_loss: 0.2658 - learning_rate: 1.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8723 - loss: 0.4176 - val_accuracy: 0.9256 - val_loss: 0.2649 - learning_rate: 1.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8660 - loss: 0.4281 - val_accuracy: 0.9247 - val_loss: 0.2636 - learning_rate: 1.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8675 - loss: 0.4294 - val_accuracy: 0.9256 - val_loss: 0.2623 - learning_rate: 1.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m598/598\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8665 - loss: 0.4166 - val_accuracy: 0.9239 - val_loss: 0.2620 - learning_rate: 1.0000e-05\n",
      "Training finished.\n",
      "Final validation accuracy: 92.64%\n"
     ]
    }
   ],
   "source": [
    "ft_history = ft_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks\n",
    ").history\n",
    "\n",
    "print('Training finished.')\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "ft_final_val_accuracy = round(max(ft_history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {ft_final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file\n",
    "ft_model.save('weights.keras')\n",
    "\n",
    "# Free memory by deleting the model instance\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YES9mYNvzdSo"
   },
   "source": [
    "## âœ… Verify that the weights work as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDrXpqfUzexe",
    "outputId": "399ad404-a369-4014-e6ac-1e329ef352f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Validation Accuracy: 0.9264\n",
      "Test Accuracy: 0.9105\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = tfk.models.load_model('weights.keras')\n",
    "\n",
    "# Predict on test set and validation set\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_val = model.predict(X_val)\n",
    "\n",
    "# Convert to class labels\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "y_pred_val_classes = np.argmax(y_pred_val, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "y_val_classes = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Compute accuracy\n",
    "test_accuracy = np.sum(y_test_classes == y_pred_test_classes) / len(y_test_classes)\n",
    "val_accuracy = np.sum(y_val_classes == y_pred_val_classes) / len(y_val_classes)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNp6pUZuddqC"
   },
   "source": [
    "## ğŸ“Š Create the model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKT4h-9xYwiT",
    "outputId": "6917d792-db37-46d2-b27c-cac99d5c0bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.neural_network = tfk.models.load_model('weights.keras')\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = self.neural_network.predict(X)\n",
    "        if len(preds.shape) == 2:\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CircvnFi4nX_"
   },
   "source": [
    "## ğŸ“ Export the ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s18kX1uDconq",
    "outputId": "c37b89f8-0737-4ecc-b4aa-870daf7bc476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model.py (deflated 48%)\n",
      "  adding: weights.keras (deflated 9%)\n"
     ]
    }
   ],
   "source": [
    "# Set filename for the zip file\n",
    "from datetime import datetime\n",
    "filename = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}.zip'\n",
    "\n",
    "# Create a zip file with the provided filename, containing model and weights\n",
    "!zip {filename} model.py weights.keras"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
